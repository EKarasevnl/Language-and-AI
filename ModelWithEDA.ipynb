{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284063/2017340903.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.autonotebook import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"lai-data/political_leaning.csv\"\n",
    "FEATURE = \"political_leaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics = pd.read_csv(DATA_PATH).iloc[:1000] # remove iloc to test full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>t2_4vpin</td>\n",
       "      <td>which added a conformal spine fuel tank, those...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>t2_4vpin</td>\n",
       "      <td>China truly was following its no first use dec...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>t2_4vpin</td>\n",
       "      <td>essentially sonic booms as they operate) and i...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>t2_4vpin</td>\n",
       "      <td>you do, the weight of ice along with the body ...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>t2_4vpin</td>\n",
       "      <td>have been Fin stabilized missiles through a [s...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auhtor_ID                                               post  \\\n",
       "0    t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1    t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2    t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3    t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4    t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "..           ...                                                ...   \n",
       "995     t2_4vpin  which added a conformal spine fuel tank, those...   \n",
       "996     t2_4vpin  China truly was following its no first use dec...   \n",
       "997     t2_4vpin  essentially sonic booms as they operate) and i...   \n",
       "998     t2_4vpin  you do, the weight of ice along with the body ...   \n",
       "999     t2_4vpin  have been Fin stabilized missiles through a [s...   \n",
       "\n",
       "    political_leaning  \n",
       "0               right  \n",
       "1               right  \n",
       "2               right  \n",
       "3               right  \n",
       "4               right  \n",
       "..                ...  \n",
       "995            center  \n",
       "996            center  \n",
       "997            center  \n",
       "998            center  \n",
       "999            center  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_politics['post'], df_politics[FEATURE],test_size= 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BoW SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('svc', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       1.00      0.97      0.99       306\n",
      "        left       1.00      0.73      0.84        11\n",
      "       right       0.88      0.99      0.93        83\n",
      "\n",
      "    accuracy                           0.97       400\n",
      "   macro avg       0.96      0.90      0.92       400\n",
      "weighted avg       0.97      0.97      0.97       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BoW SVC with EDA\n",
    "### 2.1 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/egor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "class SynonymReplacementTransformer(TransformerMixin):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def synonym_replacement(self, sentence):\n",
    "        words = sentence.split()\n",
    "\n",
    "        self.n = int(self.p * len(sentence))\n",
    "        for _ in range(self.n):\n",
    "            idx = random.randint(0, len(words) - 1)\n",
    "            word = words[idx]\n",
    "            synonyms = [syn.name() for syn in wordnet.synsets(word)]\n",
    "            if synonyms:\n",
    "                replacement = random.choice(synonyms)\n",
    "                words[idx] = replacement\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self.synonym_replacement(sentence) for sentence in X]\n",
    "    \n",
    "class RandomInsertionTransformer(TransformerMixin):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def random_insertion(self, sentence):\n",
    "        words = sentence.split()\n",
    "        self.n = int(self.p * len(sentence))\n",
    "        for _ in range(self.n):\n",
    "            idx = random.randint(0, len(words) - 1)\n",
    "            word = words[idx]\n",
    "            \n",
    "            # Get synonyms of the word that are not stop words\n",
    "            synonyms = [syn.name() for syn in wordnet.synsets(word) if syn.name() not in nltk.corpus.stopwords.words('english')]\n",
    "            \n",
    "            if synonyms:\n",
    "                synonym = random.choice(synonyms)\n",
    "                words.insert(random.randint(0, len(words)), synonym)\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self.random_insertion(sentence) for sentence in X]\n",
    "\n",
    "class RandomSwapTransformer(TransformerMixin):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def random_swap(self, sentence):\n",
    "        words = sentence.split()\n",
    "        self.n = int(self.p * len(sentence))\n",
    "        for _ in range(self.n):\n",
    "            idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "            words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self.random_swap(sentence) for sentence in X]\n",
    "\n",
    "class RandomDeletionTransformer(TransformerMixin):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def random_deletion(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words = [word for word in words if random.uniform(0, 1) > self.p]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self.random_deletion(sentence) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p - % of the sentence to be augmented (good values - 1%, 2%, 5%, 10%, 20%)\n",
    "\n",
    "synonym_replacement_transformer = SynonymReplacementTransformer(p=0.2)\n",
    "random_insertion_transformer = RandomInsertionTransformer(p=0.2)\n",
    "random_swap_transformer = RandomSwapTransformer(p=0.2)\n",
    "random_deletion_transformer = RandomDeletionTransformer(p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68b939d56ac4d0fa618d50059e8a818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "n_aug = 4 # The number of augmented instances of a sentence (good values - 2, 4, 8, 16)\n",
    "\n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "for sentence, label in tqdm(zip(X_train, y_train)):\n",
    "    # augmented_sentences = [sentence]  # Keep the original sentence\n",
    "    augmented_sentences = []\n",
    "    sentence = ' '.join([word for word in sentence.split() if word.lower() not in stop_words])\n",
    "\n",
    "    for _ in range(n_aug):\n",
    "        chosen_operation = random.choice(['SR', 'RI' 'RS', 'RD'])  \n",
    "\n",
    "        if chosen_operation == 'SR':\n",
    "            augmented_sentences.append(synonym_replacement_transformer.transform([sentence])[0])\n",
    "        elif chosen_operation == 'RI':\n",
    "            # augmented_sentences.append(random_insertion_transformer.transform([sentence])[0]) # Insertions take too long\n",
    "            augmented_sentences.append(sentence)\n",
    "        elif chosen_operation == 'RS':\n",
    "            augmented_sentences.append(random_swap_transformer.transform([sentence])[0])\n",
    "        elif chosen_operation == 'RD':\n",
    "            augmented_sentences.append(random_deletion_transformer.transform([sentence])[0])\n",
    "\n",
    "    X_train_augmented.extend(augmented_sentences)\n",
    "    y_train_augmented.extend([label] * len(augmented_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 BoW SVC with EDA model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/egor/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your pipeline with data augmentation\n",
    "clfEDA = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "# Fit the model with augmented data\n",
    "clfEDA.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       1.00      0.97      0.98       306\n",
      "        left       1.00      0.73      0.84        11\n",
      "       right       0.86      0.99      0.92        83\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.95      0.89      0.92       400\n",
      "weighted avg       0.97      0.96      0.97       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfEDA.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
