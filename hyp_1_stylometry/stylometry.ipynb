{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51d30f7",
   "metadata": {
    "id": "e51d30f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: optuna in /home/dbalm/miniconda3/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: numpy in /home/dbalm/.local/lib/python3.10/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: PyYAML in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: colorlog in /home/dbalm/miniconda3/lib/python3.10/site-packages (from optuna) (6.8.0)\n",
      "Requirement already satisfied: Mako in /home/dbalm/miniconda3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/dbalm/miniconda3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.9.0\n"
     ]
    }
   ],
   "source": [
    "# INSTALL IF NEEDED:\n",
    "\n",
    "!pip install emoji optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "xa5Ci0q_bF6o",
   "metadata": {
    "id": "xa5Ci0q_bF6o"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CONNECT TO COLAB IF NEEDED:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# CONNECT TO COLAB IF NEEDED:\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('./drive/MyDrive/data/tue_lai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090ae22",
   "metadata": {
    "id": "e090ae22"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb07990",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ecb07990",
    "outputId": "4fecf845-a861-451e-dc17-84c84de6cac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auhtor_ID                                               post   \n",
       "0  t2_7ramzeng  You can \"buy\" the show and stream it through t...  \\\n",
       "1  t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2  t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3  t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4  t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "\n",
       "  political_leaning  \n",
       "0             right  \n",
       "1             right  \n",
       "2             right  \n",
       "3             right  \n",
       "4             right  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('../../lai-data')\n",
    "data_path = 'political_leaning.csv'  # gender / feeling_thinking\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gDfZp3V6fqKC",
   "metadata": {
    "id": "gDfZp3V6fqKC"
   },
   "outputs": [],
   "source": [
    "TARGET_COL = 'political_leaning'  # change for other datasets\n",
    "CLASS_SIZE = 500\n",
    "data_samples = []\n",
    "\n",
    "for val in data[TARGET_COL].unique():\n",
    "    data_samples.append(data[data[TARGET_COL] == val].sample(CLASS_SIZE))\n",
    "data = pd.concat(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "v1z_4JdC1e8i",
   "metadata": {
    "id": "v1z_4JdC1e8i"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INDEPENDENT_COL = 'post'\n",
    "\n",
    "\n",
    "def label_encode(df, col_name):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[col_name] = label_encoder.fit_transform(df[col_name])\n",
    "    return df, label_encoder\n",
    "\n",
    "\n",
    "df, le = label_encode(data, TARGET_COL)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[INDEPENDENT_COL], df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6-eaE3phphav",
   "metadata": {
    "id": "6-eaE3phphav"
   },
   "source": [
    "## Data Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8ea73a",
   "metadata": {
    "id": "ff8ea73a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dbalm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/dbalm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import string\n",
    "import emoji\n",
    "import numpy as np\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a20f966",
   "metadata": {
    "id": "3a20f966"
   },
   "outputs": [],
   "source": [
    "class StylometryFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        stylometry_features = []\n",
    "        for text in X:\n",
    "            # Tokenize sentences and words\n",
    "            sentences = [word_tokenize(sentence) for sentence in sent_tokenize(text)]\n",
    "            words = [word for sentence in sentences for word in sentence]\n",
    "\n",
    "            # Basic stylometry features\n",
    "            features = {\n",
    "                'sentence_count': len(sentences),\n",
    "                'word_count': len(words),\n",
    "                'avg_sentence_length': len(words) / len(sentences) if len(sentences) > 0 else 0,\n",
    "                'avg_word_length': sum(len(word) for word in words) / len(words) if len(words) > 0 else 0,\n",
    "                'num_punctuation': sum(1 for char in text if char in string.punctuation),\n",
    "                'num_uppercase': sum(1 for char in text if char.isupper()),\n",
    "                'num_digits': sum(1 for char in text if char.isdigit()),\n",
    "                'num_emojis': len([char for char in text if char in emoji.EMOJI_DATA])\n",
    "            }\n",
    "\n",
    "            stylometry_features.append(features)\n",
    "\n",
    "        return pd.DataFrame(stylometry_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-ZR_uLE4yUqb",
   "metadata": {
    "id": "-ZR_uLE4yUqb"
   },
   "outputs": [],
   "source": [
    "def get_single_pipeline_data(transformer):\n",
    "    output = dict()\n",
    "    X_processed = transformer.fit_transform(X_train)\n",
    "    split = train_test_split(X_processed, y_train, test_size=0.25,random_state=42)\n",
    "    output['X_train'], output['X_val'], output['y_train'], output['y_val'] = split\n",
    "    output['X_test'] = transformer.transform(X_test)\n",
    "    return output\n",
    "\n",
    "def get_pipeline_data():\n",
    "    result = dict()\n",
    "\n",
    "    bow_transformer = Pipeline([\n",
    "    ('bow', CountVectorizer(stop_words='english')),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "    ])\n",
    "    result['bow'] = get_single_pipeline_data(CountVectorizer(stop_words='english'))\n",
    "\n",
    "    style_bow_transformer = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', CountVectorizer(stop_words='english')),\n",
    "        ('stylometry', StylometryFeatureExtractor())\n",
    "    ])),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "    ])\n",
    "    result['style_bow'] = get_single_pipeline_data(style_bow_transformer)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "OgOq7c4nyUfe",
   "metadata": {
    "id": "OgOq7c4nyUfe"
   },
   "outputs": [],
   "source": [
    "pipelines_data = get_pipeline_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34332e",
   "metadata": {
    "id": "8c34332e"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc5c0743",
   "metadata": {
    "id": "fc5c0743"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_clf(clf, X, y_true, classes, normalize=True, cmap=plt.cm.Blues):\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    print(y_pred.shape, y_true.shape)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized Confusion Matrix'\n",
    "    else:\n",
    "        title = 'Confusion Matrix'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "QlVMT504v48C",
   "metadata": {
    "id": "QlVMT504v48C"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "xgb.set_config(verbosity=1)\n",
    "SEED = 0\n",
    "\n",
    "\n",
    "def xgb_objective(trial, data_type, use_gpu=True):\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 3,\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 20),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'n_jobs': -1 if not use_gpu else None,\n",
    "        'device': \"cuda\" if use_gpu else None\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, random_state=42)\n",
    "    model.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "    y_pred = model.predict(pipelines_data[data_type]['X_val'])\n",
    "    accuracy = accuracy_score(pipelines_data[data_type]['y_val'], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def rf_objective(trial, data_type):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 20, log=True)\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    model.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "    y_pred = model.predict(pipelines_data[data_type]['X_val'])\n",
    "    accuracy = accuracy_score(pipelines_data[data_type]['y_val'], y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "RHAasZ_wvRPs",
   "metadata": {
    "id": "RHAasZ_wvRPs"
   },
   "outputs": [],
   "source": [
    "def rf_finetuning(data_type='bow'):\n",
    "    partial_objective_rf = partial(rf_objective, data_type=data_type)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(partial_objective_rf, n_trials=100)\n",
    "\n",
    "    best_model = RandomForestClassifier(random_state=SEED, **study.best_params)\n",
    "    best_model.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "    return best_model\n",
    "\n",
    "def xgb_finetuning(data_type='bow'):\n",
    "    partial_objective_xgb = partial(xgb_objective, data_type=data_type)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(partial_objective_xgb, n_trials=10)\n",
    "\n",
    "    best_model = XGBClassifier(random_state=SEED, **study.best_params)\n",
    "    best_model.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1zEU7CW9p729",
   "metadata": {
    "id": "1zEU7CW9p729"
   },
   "source": [
    "## Training & evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TOCA1B4Kn2rw",
   "metadata": {
    "id": "TOCA1B4Kn2rw"
   },
   "source": [
    "### No Style SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_VIqemcjn05a",
   "metadata": {
    "id": "_VIqemcjn05a"
   },
   "outputs": [],
   "source": [
    "data_type = 'bow'\n",
    "clf_base = LinearSVC(max_iter=10 ** 5)\n",
    "clf_base.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "evaluate_clf(clf_base, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eBaXQHDiFTVu",
   "metadata": {
    "id": "eBaXQHDiFTVu"
   },
   "source": [
    "### No Style RF/XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwtqdzdQFYSI",
   "metadata": {
    "id": "kwtqdzdQFYSI"
   },
   "outputs": [],
   "source": [
    "data_type = 'bow'\n",
    "bow_rf = rf_finetuning(data_type)\n",
    "evaluate_clf(bow_rf, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wDUluzePGkoa",
   "metadata": {
    "id": "wDUluzePGkoa"
   },
   "outputs": [],
   "source": [
    "data_type = 'bow'\n",
    "bow_xgb = xgb_finetuning(data_type)\n",
    "evaluate_clf(bow_xgb, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cHEhmfuwFOTE",
   "metadata": {
    "id": "cHEhmfuwFOTE"
   },
   "source": [
    "### Style SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cjm4-886FNJW",
   "metadata": {
    "id": "Cjm4-886FNJW"
   },
   "outputs": [],
   "source": [
    "data_type = 'style_bow'\n",
    "clf_base = LinearSVC(max_iter=10 ** 5)\n",
    "clf_base.fit(pipelines_data[data_type]['X_train'], pipelines_data[data_type]['y_train'])\n",
    "evaluate_clf(clf_base, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17634e53",
   "metadata": {
    "id": "17634e53"
   },
   "source": [
    "### Style + RF/XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwv16fQhxMfX",
   "metadata": {
    "id": "xwv16fQhxMfX"
   },
   "outputs": [],
   "source": [
    "data_type = 'style_bow'\n",
    "style_rf = rf_finetuning(data_type)\n",
    "evaluate_clf(style_rf, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C5tViMZZKNIL",
   "metadata": {
    "id": "C5tViMZZKNIL"
   },
   "outputs": [],
   "source": [
    "data_type = 'style_bow'\n",
    "style_xgb = xgb_finetuning(data_type)\n",
    "evaluate_clf(style_xgb, pipelines_data[data_type]['X_test'], y_test, classes=le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ba33e",
   "metadata": {
    "id": "x6gBSclQKhbj"
   },
   "source": [
    "## Cross validated comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a87b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "class EstimatorOpt:\n",
    "    def __init__(self, estimator, hyper_param_cv_callable, pipe_train_callable_X, pipe_train_callable_y):\n",
    "        self.hyper_cv = hyper_param_cv_callable\n",
    "        self.estimator = estimator\n",
    "        self.get_X = pipe_train_callable_X\n",
    "        self.get_y = pipe_train_callable_y\n",
    "        \n",
    "    def inner(self, inner_cv):\n",
    "        return self.hyper_cv(estimator=self.estimator, cv=inner_cv)\n",
    "    \n",
    "    def nested(self, data_pipe, inner_cv, outer_cv):\n",
    "        X = self.get_X(data_pipe)\n",
    "        y = self.get_y(data_pipe)\n",
    "        clf = self.inner(inner_cv)\n",
    "        score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "        return self.estimator, score\n",
    "\n",
    "def k_fold_nested_model_comparison(estimator_opts: List[EstimatorOpt], split_strategy: Callable, data_pipe):\n",
    "    inner_cv = split_strategy()\n",
    "    outer_cv = split_strategy()\n",
    "    results = [estimator_opt.nested(data_pipe, outer_cv, inner_cv) for estimator_opt in estimator_opts]\n",
    "    return results\n",
    "\n",
    "def optuna_search_callable(param_distr, trials):\n",
    "    return lambda estimator, cv: optuna.integration.OptunaSearchCV(estimator=estimator, \n",
    "                                                                   param_distributions=param_distr, \n",
    "                                                                   cv=cv,\n",
    "                                                                   n_trials=trials,\n",
    "                                                                   random_state=42\n",
    "                                                                  )\n",
    "\n",
    "def stratified_k_fold_strategy(n_splits, shuffle, random_state):\n",
    "    return lambda: StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "def obtain_x(data_type):\n",
    "    return lambda data: data[data_type]['X_train']\n",
    "\n",
    "def obtain_y(data_type):\n",
    "    return lambda data: data[data_type]['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6285/941858601.py:28: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  return lambda estimator, cv: optuna.integration.OptunaSearchCV(estimator=estimator,\n",
      "/home/dbalm/miniconda3/lib/python3.10/site-packages/sklearn/base.py:110: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  new_object = klass(**new_object_params)\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 20, log=True),\n",
    "    'n_estimators': optuna.distributions.IntDistribution(10, 1000)\n",
    "}\n",
    "\n",
    "rf_bow = RandomForestClassifier()\n",
    "bow_search_rf =  optuna_search_callable(rf_params, trials=100)\n",
    "rf_bow_opt = EstimatorOpt(rf_bow, bow_search_rf, obtain_x('bow'), obtain_y('bow'))\n",
    "\n",
    "stratified_kf = stratified_k_fold_strategy(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "estimator_opts = [\n",
    "    rf_bow_opt\n",
    "]\n",
    "\n",
    "k_fold_nested_model_comparison(estimator_opts, stratified_kf, pipelines_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9fdca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "e090ae22",
    "6-eaE3phphav",
    "e32fdb11",
    "8c34332e",
    "1zEU7CW9p729",
    "TOCA1B4Kn2rw",
    "8c58e9a9",
    "583941c6",
    "95530ca4",
    "NA2rw2z_r4Ga",
    "17634e53",
    "fNtsZbCtxNEa"
   ],
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
