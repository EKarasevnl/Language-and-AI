{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e51d30f7"
      },
      "outputs": [],
      "source": [
        "# !pip install skorch spacy"
      ],
      "id": "e51d30f7"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xa5Ci0q_bF6o"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('./drive/MyDrive/data/tue_lai')"
      ],
      "id": "xa5Ci0q_bF6o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e090ae22"
      },
      "source": [
        "# Load the data"
      ],
      "id": "e090ae22"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ecb07990"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = 'political_leaning.csv'\n",
        "data = pd.read_csv(data_path)"
      ],
      "id": "ecb07990"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1z_4JdC1e8i"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TARGET_COL = 'political_leaning'\n",
        "INDEPENDENT_COL = 'post'\n",
        "\n",
        "def label_encode(df, col_name):\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[col_name] = label_encoder.fit_transform(df[col_name])\n",
        "    return df, label_encoder\n",
        "\n",
        "\n",
        "data_small = data.head(500)\n",
        "df, le = label_encode(data_small, TARGET_COL)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[INDEPENDENT_COL], df[TARGET_COL])"
      ],
      "id": "v1z_4JdC1e8i"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2054c6c"
      },
      "source": [
        "### Create preprocessing pipelines"
      ],
      "id": "f2054c6c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8ea73a",
        "outputId": "fcc5d9c6-9d9e-4cca-af98-b2b59f3ce5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "CENTRALITY = TfidfVectorizer()\n",
        "CORPUS_AVG_TFIDF = CENTRALITY.fit_transform(data['post'].tolist()).mean(axis=0)"
      ],
      "id": "ff8ea73a"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3a20f966"
      },
      "outputs": [],
      "source": [
        "def scale_array(array):\n",
        "    scaler = MinMaxScaler()\n",
        "    return scaler.fit_transform(np.array(array).reshape(-1,1))\n",
        "\n",
        "\n",
        "class StylometricFeatures(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A class to extract the following stylometric features:\n",
        "    1. avg sentence/token lengths,\n",
        "    2. avg stopwords ratio,\n",
        "    3. frequencies of POS tags.\n",
        "\n",
        "    By defeault it doesn't use tfidf, but there is a parameter to do so.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, include_tfidf=False):\n",
        "        self.include_tfidf = include_tfidf\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def tfidf_centrality(self, text):\n",
        "        text_matrix = CENTRALITY.transform(text)\n",
        "        text_tf = text_matrix.sum(axis=0)\n",
        "        result = np.sum((text_tf - CORPUS_AVG_TFIDF))\n",
        "        return result\n",
        "\n",
        "\n",
        "    def stop_word_ratio(self, post):\n",
        "        return len([word for word in post if word in STOP_WORDS]) / len(post)\n",
        "\n",
        "    def avg_word_length(self, post):\n",
        "        return sum(len(word) for word in post) / len(post)\n",
        "\n",
        "    def avg_sent_length(self, post):\n",
        "        return sum(len(sent) for sent in post) / len(post)\n",
        "\n",
        "    def part_of_speech_distribution(self, text):\n",
        "        words = word_tokenize(text)\n",
        "        pos_tags = pos_tag(words)\n",
        "        pos_freq = FreqDist(tag for word, tag in pos_tags)\n",
        "        top_tags = pos_freq.most_common(20)\n",
        "        total_tags = sum(pos_freq.values())\n",
        "        pos_distribution = {tag: freq / total_tags for tag, freq in top_tags}\n",
        "        vals = list(pos_distribution.values())\n",
        "        padded = vals + [0.0] * (20 - len(vals)) # for varied length texts\n",
        "        return padded\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Add temporary vars\n",
        "        sentences = [sent_tokenize(text) for text in X]\n",
        "        words = [word_tokenize(text) for text in X]\n",
        "\n",
        "        # Calculate stylometric features\n",
        "        stylometric_features = []\n",
        "\n",
        "        avg_sent_length = scale_array([self.avg_word_length(post) for post in sentences])\n",
        "        stylometric_features.append(avg_sent_length)\n",
        "\n",
        "        avg_word_length = scale_array([self.avg_word_length(post) for post in words])\n",
        "        stylometric_features.append(avg_word_length)\n",
        "\n",
        "        stopwords_ratio = scale_array([self.stop_word_ratio(post) for post in words])\n",
        "        stylometric_features.append(stopwords_ratio)\n",
        "\n",
        "        pos_dists = [self.part_of_speech_distribution(text) for text in X]\n",
        "\n",
        "        if self.include_tfidf:\n",
        "            tfidf_val = scale_array([self.tfidf_centrality(x) for x in words])\n",
        "            stylometric_features.append(tfidf_val)\n",
        "\n",
        "        # List of cols --> list of rows\n",
        "        stylometric_features = list(map(list, zip(*stylometric_features)))\n",
        "        stylometric_features = [[float(val) for val in row] for row in stylometric_features]\n",
        "\n",
        "        feats = [\n",
        "            style_vals + pos_vals\n",
        "            for style_vals, pos_vals in zip(\n",
        "                stylometric_features,\n",
        "                pos_dists\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        return np.array(feats)"
      ],
      "id": "3a20f966"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ac7328e0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "SPACY = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "class PosFeatures(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A class to extract POS features: for each post returns a list of corresponding POS tags\n",
        "    \"\"\"\n",
        "    def __init__(self, include_tfidf=False, length_percentile=95):\n",
        "        self.include_tfidf = include_tfidf\n",
        "        self.length_percentile = length_percentile\n",
        "        self._standartization_factor = 0\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        assert (self.sentence_size is not None), \"Fitting required\"\n",
        "\n",
        "        # Create the output matrix\n",
        "        result = np.zeros((len(X), self.sentence_size), dtype='uint8')\n",
        "\n",
        "        for i, x in enumerate(SPACY.pipe(X, batch_size=50)):\n",
        "            # Store the POS-tags\n",
        "            tags = np.fromiter((token.pos for token in x), dtype='uint8', count=len(x))\n",
        "\n",
        "            # Pad and truncate data, if necessary, and store them in result\n",
        "            last_index = len(tags) if len(tags) < self.sentence_size else self.sentence_size\n",
        "            result[i, :last_index] = tags[:last_index]\n",
        "\n",
        "        # Generate the factor one time to ensure applying the same factor at the next transformations\n",
        "        if self._standartization_factor == 0:\n",
        "            self._standartization_factor = np.min(result[result != 0]) - 1\n",
        "\n",
        "        # Standartize all valid elements to count from 1\n",
        "        result[result != 0] -= self._standartization_factor\n",
        "        return result\n",
        "\n",
        "    def fit(self, X, *_):\n",
        "        # Define an optimal sentence size covering a specific percent of all sample\n",
        "        self.sentence_size = int(np.percentile([len(t.split()) for t in X], self.length_percentile))\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, *_):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "id": "ac7328e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e32fdb11"
      },
      "source": [
        "# Create custom classifiers"
      ],
      "id": "e32fdb11"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5daa2fdc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, rnn_type, hidden_size, output_size, input_size, dropout, num_layers, bidirectional):\n",
        "        super().__init__()\n",
        "        assert (rnn_type in ['gru', 'lstm', 'simple']), \"Invalid RNN type\"\n",
        "\n",
        "        rnn_params = {\n",
        "            \"hidden_size\": hidden_size,\n",
        "            \"input_size\": input_size,\n",
        "            \"dropout\": dropout,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"bidirectional\": bidirectional\n",
        "        }\n",
        "\n",
        "        if rnn_type == 'gru':\n",
        "            self.rnn = nn.GRU(**rnn_params)\n",
        "        elif rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTM(**rnn_params)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(**rnn_params)\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.fc = nn.Linear(\n",
        "            (1 + bidirectional) * hidden_size,\n",
        "            output_size\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        batch_size, seq_len, input_size = input_seq.shape\n",
        "\n",
        "        if self.rnn_type == 'lstm':\n",
        "            rnn_output, (last_hidden_state, last_cell_state) = self.rnn(input_seq)\n",
        "        else:\n",
        "            rnn_output, last_hidden_stwate = self.rnn(input_seq)\n",
        "\n",
        "        last_output = rnn_output[:, -1, :]\n",
        "        output = self.fc(last_output).view(batch_size, -1)\n",
        "        output_probs = self.softmax(output)\n",
        "        return output_probs\n"
      ],
      "id": "5daa2fdc"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lBz4jNvnuYHm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class RnnSklearnWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self,\n",
        "                 batch_size=32,\n",
        "                 epochs=3,\n",
        "                 dropout=0,\n",
        "                 rnn_type='gru',\n",
        "                 hidden_size=300,\n",
        "                 num_layers=1,\n",
        "                 bidirectional=False):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.dropout = dropout\n",
        "        self.rnn_type = rnn_type\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self._model = None\n",
        "\n",
        "    def fit(self, X, Y=None):\n",
        "        assert (Y is not None), \"Y is required\"\n",
        "        self.num_tags = np.max(X) + 1\n",
        "\n",
        "        rnn_params = {\n",
        "            \"rnn_type\": self.rnn_type,\n",
        "            \"input_size\": self.num_tags,\n",
        "            \"output_size\": np.max(Y) + 1,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"dropout\": self.dropout,\n",
        "            \"num_layers\": self.num_layers,\n",
        "            \"bidirectional\": self.bidirectional\n",
        "        }\n",
        "        self.model = RNNClassifier(**rnn_params).to(DEVICE)\n",
        "        self.model.train()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=0.001, weight_decay=0.9)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        step = 0\n",
        "        for _ in range(self.epochs):\n",
        "            running_loss = 0\n",
        "            for X_batch, y_batch in DataLoader(list(zip(X, Y)), batch_size=self.batch_size, shuffle=True):\n",
        "                X_batch, y_batch = self.one_hot_encode(X_batch, self.num_tags).float().to(DEVICE), y_batch.long().to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                out = self.model(X_batch)\n",
        "                loss = criterion(out, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                step += 1\n",
        "                running_loss += loss.item()\n",
        "                if step % 10 == 0:\n",
        "                    last_loss = running_loss / 50\n",
        "                    print('Batch {} loss: {}'.format(step, last_loss))\n",
        "                    running_loss = 0.\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, y=None):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Fitting required before prediction!\")\n",
        "\n",
        "        self.model.eval()\n",
        "        preds = []\n",
        "        for X_batch in DataLoader(X, batch_size=self.batch_size):\n",
        "            X_batch = self.one_hot_encode(X_batch, self.num_tags).float().to(DEVICE)\n",
        "            print(X_batch.shape)\n",
        "            output = self.model.forward(X_batch)\n",
        "            preds.append(output)\n",
        "\n",
        "        preds = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
        "        return np.argmax(preds, axis=1)\n",
        "\n",
        "\n",
        "    def one_hot_encode(self, tensor, num_classes):\n",
        "        batch_size, seq_len = tensor.size()\n",
        "        eye = torch.eye(num_classes)\n",
        "        one_hot_encoded = eye[tensor.long()]\n",
        "        one_hot_encoded = one_hot_encoded.view(batch_size, seq_len, num_classes)\n",
        "        return one_hot_encoded"
      ],
      "id": "lBz4jNvnuYHm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c34332e"
      },
      "source": [
        "### Evaluate"
      ],
      "id": "8c34332e"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fc5c0743"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_clf(clf, X, y_true, classes, normalize=True, cmap=plt.cm.Blues):\n",
        "    y_pred = clf.predict(X)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title = 'Normalized Confusion Matrix'\n",
        "    else:\n",
        "        title = 'Confusion Matrix'\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "fc5c0743"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa6322fd"
      },
      "source": [
        "# Training & evaluating"
      ],
      "id": "aa6322fd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f6fb783"
      },
      "source": [
        "### Baseline: TFIDF with SVM"
      ],
      "id": "4f6fb783"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7d32621"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC()\n",
        "\n",
        "\n",
        "clf_base = Pipeline([\n",
        "    ('features', StylometricFeatures()),\n",
        "    ('classifier', svm)\n",
        "])"
      ],
      "id": "c7d32621"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "bdba503b",
        "outputId": "58b039a8-c902-44ca-af4b-c26fdd8fd964"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;, StylometricFeatures()),\n",
              "                (&#x27;classifier&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;, StylometricFeatures()),\n",
              "                (&#x27;classifier&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StylometricFeatures</label><div class=\"sk-toggleable__content\"><pre>StylometricFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('features', StylometricFeatures()),\n",
              "                ('classifier', LinearSVC())])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_base.fit(X_train, y_train)"
      ],
      "id": "bdba503b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1153f10f"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(clf_base, X_test, y_test, classes=le.classes_)"
      ],
      "id": "1153f10f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c58e9a9"
      },
      "source": [
        "### Pure stylometry 1: StylometryFeatrues + RandomForest"
      ],
      "id": "8c58e9a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41373e43"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    max_depth=2, random_state=0\n",
        ")\n",
        "\n",
        "clf_style_rf = Pipeline([\n",
        "    ('features',  StylometricFeatures()),\n",
        "    ('classifier', rf)\n",
        "])"
      ],
      "id": "41373e43"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf9f8af5"
      },
      "outputs": [],
      "source": [
        "clf_style_rf.fit(X_train, y_train)"
      ],
      "id": "cf9f8af5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607cd763"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(clf_style_rf, X_test, y_test, classes=le.classes_)"
      ],
      "id": "607cd763"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "583941c6"
      },
      "source": [
        "### Pure stylometry 2.0: PosFeatrues + RandomForest"
      ],
      "id": "583941c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac47ced5"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(\n",
        "    max_depth=2, random_state=0\n",
        ")\n",
        "\n",
        "clf_pos_rf = Pipeline([\n",
        "        ('pre', PosFeatures()),\n",
        "        ('rf', rf)\n",
        "])"
      ],
      "id": "ac47ced5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "2c5559bc",
        "outputId": "be22fbcd-60f1-4035-9451-fcc824a20f30"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pre&#x27;, PosFeatures()),\n",
              "                (&#x27;rf&#x27;, RandomForestClassifier(max_depth=2, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pre&#x27;, PosFeatures()),\n",
              "                (&#x27;rf&#x27;, RandomForestClassifier(max_depth=2, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PosFeatures</label><div class=\"sk-toggleable__content\"><pre>PosFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=2, random_state=0)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('pre', PosFeatures()),\n",
              "                ('rf', RandomForestClassifier(max_depth=2, random_state=0))])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_pos_rf.fit(X_train, y_train)"
      ],
      "id": "2c5559bc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "829d7560"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(clf_pos_rf, X_test, y_test, classes=le.classes_)"
      ],
      "id": "829d7560"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95530ca4"
      },
      "source": [
        "### Pure stylometry 2.1: PosFeatrues + RNN"
      ],
      "id": "95530ca4"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0e2ceb4a"
      },
      "outputs": [],
      "source": [
        "rnn = RnnSklearnWrapper(\n",
        "    epochs=5,\n",
        "    rnn_type='gru',\n",
        "    dropout=0.3,\n",
        "    num_layers=3,\n",
        "    bidirectional=True\n",
        ")\n",
        "\n",
        "\n",
        "clf_pos_rnn = Pipeline([\n",
        "        ('pre', PosFeatures()),\n",
        "        ('rnn', rnn)\n",
        "])"
      ],
      "id": "0e2ceb4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8a9b0f4"
      },
      "outputs": [],
      "source": [
        "clf_pos_rnn.fit(X_train, y_train)"
      ],
      "id": "f8a9b0f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b436e46"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(clf_pos_rnn, X_test, y_test, classes=le.classes_)"
      ],
      "id": "4b436e46"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17634e53"
      },
      "source": [
        "### Stylometry with TFIDF 1:  StylometryFeatrues + RandomForest"
      ],
      "id": "17634e53"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8df6cb67"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    max_depth=2, random_state=0\n",
        ")\n",
        "\n",
        "clf_style_rf = Pipeline([\n",
        "    ('features', StylometricFeatures(include_tfidf=True)),\n",
        "    ('classifier', rf)\n",
        "])"
      ],
      "id": "8df6cb67"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "64a2b253",
        "outputId": "ae2d2070-b99c-4ce6-eddd-6115223fdde2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;, StylometricFeatures(include_tfidf=True)),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 RandomForestClassifier(max_depth=2, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;, StylometricFeatures(include_tfidf=True)),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 RandomForestClassifier(max_depth=2, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StylometricFeatures</label><div class=\"sk-toggleable__content\"><pre>StylometricFeatures(include_tfidf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=2, random_state=0)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('features', StylometricFeatures(include_tfidf=True)),\n",
              "                ('classifier',\n",
              "                 RandomForestClassifier(max_depth=2, random_state=0))])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_style_rf.fit(X_train, y_train)"
      ],
      "id": "64a2b253"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce23f251"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(clf_style_rf, X_test, y_test, classes=le.classes_)"
      ],
      "id": "ce23f251"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Pe9xEIhZhm"
      },
      "outputs": [],
      "source": [],
      "id": "d9Pe9xEIhZhm"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e090ae22",
        "e32fdb11",
        "4f6fb783",
        "8c58e9a9",
        "583941c6",
        "17634e53"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}